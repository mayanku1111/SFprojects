{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayanku1111/SFprojects/blob/main/Copy_of_Copy_of_cross.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nRQ_lPLjV5lF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6495bd-7eeb-411f-cfdf-05e02b8659f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CrossInitialization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpYHfR_QYDoS",
        "outputId": "2ab3df26-3750-487a-8717-5d102469c6eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CrossInitialization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJy_ZqzEYDr-",
        "outputId": "419494dc-95dd-42ae-a3f2-82a299953f33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t\t\t\t models\t\t     textual_inversion_dataset.py  tristan_images4\n",
            "examples\t\t\t __pycache__\t     train_cross_init.py\t   utils.py\n",
            "learned_embeddingsTristanthrush  README.md\t     tristan_images\n",
            "LICENSE\t\t\t\t requirements.txt    tristan_images2\n",
            "logs\t\t\t\t test_cross_init.py  tristan_images3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CrossInitialization')"
      ],
      "metadata": {
        "id": "J0VzI0VVYDud"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSXN3XPGYDw-",
        "outputId": "28e2220a-74a6-4342-ec61-833d9133e869"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.21.2 (from diffusers[torch]==0.21.2->-r requirements.txt (line 1))\n",
            "  Downloading diffusers-0.21.2.tar.gz (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.20.3 (from -r requirements.txt (line 2))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.18.1+cu121)\n",
            "Collecting transformers==4.25.1 (from -r requirements.txt (line 4))\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 5))\n",
            "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (8.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (0.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (2.3.1+cu121)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1->-r requirements.txt (line 4))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1->-r requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (1.3.0)\n",
            "Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m17.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.21.2-py3-none-any.whl size=1489251 sha256=15f867063b8dbf97f52f926de506c3e291967fa0366b638c29b672e04cc1b541\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/09/32/11c9e42c397d3f3494226b28ba68c4ad4718a68a65dba14ea6\n",
            "Successfully built diffusers\n",
            "Installing collected packages: tokenizers, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, transformers, nvidia-cusolver-cu12, diffusers, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.32.1\n",
            "    Uninstalling accelerate-0.32.1:\n",
            "      Successfully uninstalled accelerate-0.32.1\n",
            "Successfully installed accelerate-0.20.3 diffusers-0.21.2 ftfy-6.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 tokenizers-0.13.3 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "r-v__a2tYD2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "640cddb8-fa0a-4dad-f88c-7cc588c89b96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CrossInitialization'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CrossInitialization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NLRDz69Zvp6",
        "outputId": "a0e47f58-2524-43b7-882a-ba1c7bbb8ed5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CrossInitialization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NO0fxWNqa-VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python test_cross_init.py \\\n",
        "#     --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "#     --num_inference_steps 50 \\\n",
        "#     --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddings/28017/learned_embeds.bin\" \\\n",
        "#     --prompt \"a {} person eating bread in front of the Eiffel Tower\" \\\n",
        "#     --save_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/28017\" \\\n",
        "#     --num_images_per_prompt=8 \\\n",
        "#     --n_iter=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmhEB8DOcOiA",
        "outputId": "ec0a523c-7959-4b51-b177-e7ad8d558532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 10:40:40.370126: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 10:40:40.370173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 10:40:40.371926: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 10:40:41.629518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 6/6 [00:07<00:00,  1.29s/it]\n",
            "100% 50/50 [00:40<00:00,  1.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python train_cross_init.py \\\n",
        "#     --save_steps 100 \\\n",
        "#     --only_save_embeds \\\n",
        "#     --placeholder_token \"<Jordan>\" \\\n",
        "#     --train_batch_size 8 \\\n",
        "#     --scale_lr \\\n",
        "#     --n_persudo_tokens 2 \\\n",
        "#     --reg_weight \"1e-5\" \\\n",
        "#     --learning_rate 0.000625 \\\n",
        "#     --max_train_step 320 \\\n",
        "#     --train_data_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/jordan\" \\\n",
        "#     --celeb_path \"/content/drive/MyDrive/CrossInitialization/examples/wiki_names_v2.txt\" \\\n",
        "#     --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "#     --output_dir \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddings\" \\"
      ],
      "metadata": {
        "id": "sD6zgY7PcOlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2dcd45-0949-4140-8686-6b9cd32aeda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 11:50:42.716233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 11:50:42.716291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 11:50:42.718291: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 11:50:42.729545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-26 11:50:44.016464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: train_cross_init.py [-h] [--save_steps SAVE_STEPS] [--only_save_embeds]\n",
            "                           --pretrained_model_name_or_path PRETRAINED_MODEL_NAME_OR_PATH\n",
            "                           [--revision REVISION] [--tokenizer_name TOKENIZER_NAME]\n",
            "                           --train_data_dir TRAIN_DATA_DIR --placeholder_token PLACEHOLDER_TOKEN\n",
            "                           [--initialize_tokens [INITIALIZE_TOKENS ...]] [--celeb_path CELEB_PATH]\n",
            "                           --n_persudo_tokens N_PERSUDO_TOKENS [--reg_weight REG_WEIGHT]\n",
            "                           [--learnable_property LEARNABLE_PROPERTY] [--repeats REPEATS]\n",
            "                           [--output_dir OUTPUT_DIR] [--seed SEED] [--resolution RESOLUTION]\n",
            "                           [--center_crop] [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                           [--max_train_steps MAX_TRAIN_STEPS]\n",
            "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                           [--gradient_checkpointing] [--learning_rate LEARNING_RATE] [--scale_lr]\n",
            "                           [--lr_scheduler LR_SCHEDULER] [--lr_warmup_steps LR_WARMUP_STEPS]\n",
            "                           [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
            "                           [--adam_weight_decay ADAM_WEIGHT_DECAY] [--adam_epsilon ADAM_EPSILON]\n",
            "                           [--push_to_hub] [--hub_token HUB_TOKEN] [--hub_model_id HUB_MODEL_ID]\n",
            "                           [--logging_dir LOGGING_DIR] [--mixed_precision {no,fp16,bf16}]\n",
            "                           [--allow_tf32] [--report_to REPORT_TO]\n",
            "                           [--validation_prompt VALIDATION_PROMPT]\n",
            "                           [--validation_prompt_file VALIDATION_PROMPT_FILE]\n",
            "                           [--num_validation_images NUM_VALIDATION_IMAGES]\n",
            "                           [--validation_steps VALIDATION_STEPS]\n",
            "                           [--validation_epochs VALIDATION_EPOCHS] [--local_rank LOCAL_RANK]\n",
            "                           [--checkpointing_steps CHECKPOINTING_STEPS]\n",
            "                           [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
            "                           [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                           [--enable_xformers_memory_efficient_attention]\n",
            "train_cross_init.py: error: unrecognized arguments: \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --logging_dir \"/content/drive/MyDrive/CrossInitialization/logs/tensorboard\" \\"
      ],
      "metadata": {
        "id": "aChCbS7WcOoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from accelerate import Accelerator\n",
        "\n",
        "# accelerator = Accelerator(log_with=\"tensorboard\", project_dir='./output')\n",
        "\n",
        "!pip install git+https://github.com/huggingface/accelerate\n"
      ],
      "metadata": {
        "id": "KZ4q6oee4x0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71956c00-b573-4ca4-cee0-204fda7fd686"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-0if1m51_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-0if1m51_\n",
            "  Resolved https://github.com/huggingface/accelerate to commit d982751aecc020a58a5583473eabe8d281f5f114\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.33.0.dev0) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.33.0.dev0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.33.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.33.0.dev0-py3-none-any.whl size=315352 sha256=fbadc06b8625b95b818337bb4ad8f219a043c9cde4b8756681c15f42905aa907\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zexc6bqk/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.20.3\n",
            "    Uninstalling accelerate-0.20.3:\n",
            "      Successfully uninstalled accelerate-0.20.3\n",
            "Successfully installed accelerate-0.33.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_cross_init.py --save_steps 100 --only_save_embeds --placeholder_token \"<Tristan>\" --train_batch_size 8 --scale_lr --n_persudo_tokens 2 --reg_weight \"1e-5\" --learning_rate 0.000625 --max_train_step 320 --train_data_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/tristan\" --celeb_path \"/content/drive/MyDrive/CrossInitialization/examples/wiki_names_v2.txt\" --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" --output_dir \"/content/drive/MyDrive/CrossInitialization/learned_embeddingsTristanthrush\""
      ],
      "metadata": {
        "id": "W2e7EkIscOq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b6ee9b-3f43-48fa-f5b0-e86d57123cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-05 19:15:00.192763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-08-05 19:15:00.210660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-05 19:15:00.232350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-05 19:15:00.238919: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-05 19:15:00.254688: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-05 19:15:01.455669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/05/2024 19:15:04 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "{'variance_type', 'timestep_spacing', 'sample_max_value', 'dynamic_thresholding_ratio', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "{'time_embedding_dim', 'num_attention_heads', 'time_embedding_act_fn', 'addition_time_embed_dim', 'time_cond_proj_dim', 'conv_in_kernel', 'time_embedding_type', 'attention_type', 'encoder_hid_dim', 'resnet_skip_time_act', 'timestep_post_act', 'dropout', 'upcast_attention', 'addition_embed_type_num_heads', 'class_embed_type', 'transformer_layers_per_block', 'conv_out_kernel', 'mid_block_type', 'class_embeddings_concat', 'resnet_out_scale_factor', 'addition_embed_type', 'resnet_time_scale_shift', 'mid_block_only_cross_attention', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type'} was not found in config. Values will be initialized to default values.\n",
            "get embeddings: 100% 691/691 [00:00<00:00, 2529.69it/s]\n",
            "08/05/2024 19:15:11 - INFO - __main__ - ***** Running training *****\n",
            "08/05/2024 19:15:11 - INFO - __main__ -   Num examples = 200\n",
            "08/05/2024 19:15:11 - INFO - __main__ -   Num Epochs = 13\n",
            "08/05/2024 19:15:11 - INFO - __main__ -   Instantaneous batch size per device = 8\n",
            "08/05/2024 19:15:11 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "08/05/2024 19:15:11 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "08/05/2024 19:15:11 - INFO - __main__ -   Total optimization steps = 320\n",
            "Steps:  31% 100/320 [04:19<09:25,  2.57s/it, embed_loss=6.02e-5, loss=0.148, lr=0.005]08/05/2024 19:19:31 - INFO - __main__ - Saving embeddings\n",
            "Steps:  62% 200/320 [08:39<05:08,  2.57s/it, embed_loss=0.000119, loss=0.17, lr=0.005]08/05/2024 19:23:50 - INFO - __main__ - Saving embeddings\n",
            "Steps:  94% 300/320 [12:58<00:51,  2.56s/it, embed_loss=0.00017, loss=0.082, lr=0.005]08/05/2024 19:28:09 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 320/320 [13:50<00:00,  2.58s/it, embed_loss=0.00018, loss=0.158, lr=0.005]08/05/2024 19:29:01 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 320/320 [13:50<00:00,  2.59s/it, embed_loss=0.00018, loss=0.158, lr=0.005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_cross_init.py --save_steps 100 --only_save_embeds --placeholder_token \"<jordanbroggi>\" --train_batch_size 8 --scale_lr --n_persudo_tokens 2 --reg_weight \"1e-5\" --learning_rate 0.000625 --max_train_step 320 --train_data_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/jordanbroggi\" --celeb_path \"/content/drive/MyDrive/CrossInitialization/examples/wiki_names_v2.txt\" --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" --output_dir \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsbroggi2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyWNFWkD2rZQ",
        "outputId": "454a7748-403d-454f-c07a-1e7086bd4465"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-06 17:58:40.519163: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-08-06 17:58:40.536838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-06 17:58:40.557862: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-06 17:58:40.564587: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-06 17:58:40.580301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-06 17:58:41.723009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/06/2024 17:58:44 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "{'sample_max_value', 'variance_type', 'timestep_spacing', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "{'addition_time_embed_dim', 'resnet_time_scale_shift', 'upcast_attention', 'time_embedding_dim', 'conv_in_kernel', 'mid_block_type', 'time_cond_proj_dim', 'time_embedding_type', 'encoder_hid_dim_type', 'class_embed_type', 'addition_embed_type_num_heads', 'timestep_post_act', 'resnet_out_scale_factor', 'transformer_layers_per_block', 'time_embedding_act_fn', 'attention_type', 'resnet_skip_time_act', 'mid_block_only_cross_attention', 'encoder_hid_dim', 'conv_out_kernel', 'class_embeddings_concat', 'cross_attention_norm', 'num_attention_heads', 'dropout', 'projection_class_embeddings_input_dim', 'addition_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "get embeddings: 100% 691/691 [00:00<00:00, 2621.87it/s]\n",
            "08/06/2024 17:58:52 - INFO - __main__ - ***** Running training *****\n",
            "08/06/2024 17:58:52 - INFO - __main__ -   Num examples = 1100\n",
            "08/06/2024 17:58:52 - INFO - __main__ -   Num Epochs = 3\n",
            "08/06/2024 17:58:52 - INFO - __main__ -   Instantaneous batch size per device = 8\n",
            "08/06/2024 17:58:52 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "08/06/2024 17:58:52 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "08/06/2024 17:58:52 - INFO - __main__ -   Total optimization steps = 320\n",
            "Steps:  31% 100/320 [04:32<09:45,  2.66s/it, embed_loss=4.24e-5, loss=0.0922, lr=0.005]08/06/2024 18:03:25 - INFO - __main__ - Saving embeddings\n",
            "Steps:  62% 200/320 [08:58<05:20,  2.67s/it, embed_loss=0.000105, loss=0.254, lr=0.005]08/06/2024 18:07:50 - INFO - __main__ - Saving embeddings\n",
            "Steps:  94% 300/320 [13:24<00:53,  2.67s/it, embed_loss=0.000155, loss=0.0688, lr=0.005]08/06/2024 18:12:16 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 320/320 [14:17<00:00,  2.66s/it, embed_loss=0.000162, loss=0.0926, lr=0.005]08/06/2024 18:13:09 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 320/320 [14:17<00:00,  2.68s/it, embed_loss=0.000162, loss=0.0926, lr=0.005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cross_init.py \\\n",
        "    --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "    --num_inference_steps 50 \\\n",
        "    --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordanbroggi/learned_embeds.bin\" \\\n",
        "    --prompt \"a photo of a {} person standing next to Trump\" \\\n",
        "    --save_dir \"/content/drive/MyDrive/CrossInitialization/jordan_images\" \\\n",
        "    --num_images_per_prompt=4 \\\n",
        "    --n_iter=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUOU1exK6qok",
        "outputId": "9899755f-7572-4e26-9bcc-c8adfe1133b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 17:52:40.704649: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 17:52:40.704705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 17:52:40.707613: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 17:52:41.949846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "model_index.json: 100% 543/543 [00:00<00:00, 3.62MB/s]\n",
            "Fetching 7 files:   0% 0/7 [00:00<?, ?it/s]\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 342/342 [00:00<00:00, 2.19MB/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 13.47it/s]\n",
            "Loading pipeline components...: 100% 6/6 [00:19<00:00,  3.25s/it]\n",
            "100% 50/50 [00:22<00:00,  2.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cross_init.py \\\n",
        "    --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "    --num_inference_steps 50 \\\n",
        "    --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/learned_embeds.bin\" \\\n",
        "    --prompt \"a photo of a {} person standing next to Jordan\" \\\n",
        "    --save_dir \"/content/drive/MyDrive/CrossInitialization/Trump_images\" \\\n",
        "    --num_images_per_prompt=4 \\\n",
        "    --n_iter=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYErR0y86q6u",
        "outputId": "2a3de49d-338c-4961-ea9c-a9951fdbb15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 18:00:40.816091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 18:00:40.816146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 18:00:40.823119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 18:00:42.801113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 6/6 [00:22<00:00,  3.77s/it]\n",
            "100% 50/50 [00:22<00:00,  2.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd method"
      ],
      "metadata": {
        "id": "OVz54erPN17g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parser.add_argument(\"--learned_embedding_path_2\", type=str, required=True)\n",
        "\n",
        "# learned_embeds_1 = torch.load(args.learned_embedding_path)\n",
        "# token_1 = list(learned_embeds_1.keys())[0]\n",
        "# learned_embeds_1 = learned_embeds_1[token_1]\n",
        "\n",
        "\n",
        "# learned_embeds_2 = torch.load(args.learned_embedding_path_2)\n",
        "# token_2 = list(learned_embeds_2.keys())[0]\n",
        "# learned_embeds_2 = learned_embeds_2[token_2]\n",
        "# num_added_tokens = tokenizer.add_tokens([token_1, token_2])\n",
        "# if num_added_tokens == 2:\n",
        "#     text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "# else:\n",
        "#     raise ValueError(f\"The tokenizer already contains the token {token_1} or {token_2}.\")\n",
        "\n",
        "# text_encoder.get_input_embeddings().weight.data[tokenizer.convert_tokens_to_ids(token_1)] = learned_embeds_1\n",
        "# text_encoder.get_input_embeddings().weight.data[tokenizer.convert_tokens_to_ids(token_2)] = learned_embeds_2\n",
        "# prompts = [p.replace(\"{1}\", token_1).replace(\"{2}\", token_2) for p in args.prompt]\n",
        "# python test_cross_init.py \\\n",
        "#     --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "#     --num_inference_steps 50 \\\n",
        "#     --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/learned_embeds.bin\" \\\n",
        "#     --learned_embedding_path_2 \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/learned_embeds.bin\" \\\n",
        "#     --prompt \"a photo of a {1} person standing next to {2}\" \\\n",
        "#     --save_dir \"./output/jordan_trump_images\" \\\n",
        "#     --num_images_per_prompt=4 \\\n",
        "#     --n_iter=1"
      ],
      "metadata": {
        "id": "aP9XB_lLN1-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cross_init.py \\\n",
        "    --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "    --num_inference_steps 50 \\\n",
        "    --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsbroggi2/learned_embeds.bin\" \\\n",
        "    --prompt \"Photorealistic portrait  of {} and Donald Trump smiling at the camera standing side by side in a formal room background The background includes curtains and decor.High detail natural lighting sharp focus\" \\\n",
        "    --save_dir \"/content/drive/MyDrive/CrossInitialization/tristan_images6\" \\\n",
        "    --num_images_per_prompt=8 \\\n",
        "    --n_iter=1"
      ],
      "metadata": {
        "id": "2SRFkDExN2Ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688ff966-dc06-49f4-d4f0-56c357fa8fe8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-06 18:28:04.296238: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-06 18:28:04.318223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-06 18:28:04.324849: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-06 18:28:05.473096: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  8.58it/s]\n",
            "100% 50/50 [00:21<00:00,  2.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cross_init.py \\\n",
        "    --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "    --num_inference_steps 50 \\\n",
        "    --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/learned_embeddingsTristanthrush/learned_embeds.bin\" \\\n",
        "    --prompt \"Photorealistic portrait  of {} and Donald Trump smiling at the camera,close-up, selfie angle.Bright sunny day background. High detail, natural lighting, sharp focus.\" \\\n",
        "    --save_dir \"/content/drive/MyDrive/CrossInitialization/tristan_images3\" \\\n",
        "    --num_images_per_prompt=8 \\\n",
        "    --n_iter=1"
      ],
      "metadata": {
        "id": "XGj2Y9A5N2IL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0561ce2-df13-420a-d234-f458d1302924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-06 14:45:01.385813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-06 14:45:01.407882: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-06 14:45:01.414641: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-06 14:45:02.608576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.70it/s]\n",
            "100% 50/50 [00:20<00:00,  2.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cross_init.py \\\n",
        "    --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "    --num_inference_steps 50 \\\n",
        "    --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/learned_embeddingsTristanthrush/learned_embeds.bin\" \\\n",
        "    --prompt \"Photorealistic portrait  of {} and Donald Trump smiling at the camera standing side by side in a formal room background The background includes curtains and decor.High detail natural lighting sharp focus.\" \\\n",
        "    --save_dir \"/content/drive/MyDrive/CrossInitialization/tristan_images5\" \\\n",
        "    --num_images_per_prompt=8 \\\n",
        "    --n_iter=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCJFqBnjjIjS",
        "outputId": "0e3e6086-ae94-44b2-82df-2f64ef4595ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-06 17:50:57.492922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-06 17:50:57.514974: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-06 17:50:57.521574: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-06 17:50:58.683575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  8.77it/s]\n",
            "100% 50/50 [00:21<00:00,  2.35it/s]\n"
          ]
        }
      ]
    }
  ]
}