{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayanku1111/SFprojects/blob/main/Copy_of_cross.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nRQ_lPLjV5lF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da70ab2-7053-441b-b399-bf7428d01020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CrossInitialization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpYHfR_QYDoS",
        "outputId": "589d68a6-e02a-4414-9dc1-6168db289487"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CrossInitialization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJy_ZqzEYDr-",
        "outputId": "cc35581a-5ba8-43a1-b35a-83f81198390a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t  LICENSE  models\tREADME.md\t  test_cross_init.py\t\ttrain_cross_init.py\n",
            "examples  logs\t   __pycache__\trequirements.txt  textual_inversion_dataset.py\tutils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CrossInitialization')"
      ],
      "metadata": {
        "id": "J0VzI0VVYDud"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSXN3XPGYDw-",
        "outputId": "e0367a92-453f-4afe-8439-8d06d4c76fb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.21.2 (from diffusers[torch]==0.21.2->-r requirements.txt (line 1))\n",
            "  Downloading diffusers-0.21.2.tar.gz (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.20.3 (from -r requirements.txt (line 2))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.18.1+cu121)\n",
            "Collecting transformers==4.25.1 (from -r requirements.txt (line 4))\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 5))\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (8.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (0.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3->-r requirements.txt (line 2)) (2.3.1+cu121)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1->-r requirements.txt (line 4))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1->-r requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.2->diffusers[torch]==0.21.2->-r requirements.txt (line 1)) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.3->-r requirements.txt (line 2)) (1.3.0)\n",
            "Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m623.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.21.2-py3-none-any.whl size=1489252 sha256=0273995f381b960b75b6b0b977fa987f049ea778e76d2de4efc9eafd83a40384\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/09/32/11c9e42c397d3f3494226b28ba68c4ad4718a68a65dba14ea6\n",
            "Successfully built diffusers\n",
            "Installing collected packages: tokenizers, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, transformers, nvidia-cusolver-cu12, diffusers, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.32.1\n",
            "    Uninstalling accelerate-0.32.1:\n",
            "      Successfully uninstalled accelerate-0.32.1\n",
            "Successfully installed accelerate-0.20.3 diffusers-0.21.2 ftfy-6.2.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 tokenizers-0.13.3 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-v__a2tYD2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CrossInitialization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NLRDz69Zvp6",
        "outputId": "8cd6b99d-84b9-49e7-d61f-9b40b9e2822e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CrossInitialization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NO0fxWNqa-VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python test_cross_init.py \\\n",
        "#     --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "#     --num_inference_steps 50 \\\n",
        "#     --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddings/28017/learned_embeds.bin\" \\\n",
        "#     --prompt \"a {} person eating bread in front of the Eiffel Tower\" \\\n",
        "#     --save_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/28017\" \\\n",
        "#     --num_images_per_prompt=8 \\\n",
        "#     --n_iter=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmhEB8DOcOiA",
        "outputId": "ec0a523c-7959-4b51-b177-e7ad8d558532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 10:40:40.370126: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 10:40:40.370173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 10:40:40.371926: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 10:40:41.629518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 6/6 [00:07<00:00,  1.29s/it]\n",
            "100% 50/50 [00:40<00:00,  1.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python train_cross_init.py \\\n",
        "#     --save_steps 100 \\\n",
        "#     --only_save_embeds \\\n",
        "#     --placeholder_token \"<Jordan>\" \\\n",
        "#     --train_batch_size 8 \\\n",
        "#     --scale_lr \\\n",
        "#     --n_persudo_tokens 2 \\\n",
        "#     --reg_weight \"1e-5\" \\\n",
        "#     --learning_rate 0.000625 \\\n",
        "#     --max_train_step 320 \\\n",
        "#     --train_data_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/jordan\" \\\n",
        "#     --celeb_path \"/content/drive/MyDrive/CrossInitialization/examples/wiki_names_v2.txt\" \\\n",
        "#     --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "#     --output_dir \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddings\" \\"
      ],
      "metadata": {
        "id": "sD6zgY7PcOlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2dcd45-0949-4140-8686-6b9cd32aeda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 11:50:42.716233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 11:50:42.716291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 11:50:42.718291: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 11:50:42.729545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-26 11:50:44.016464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: train_cross_init.py [-h] [--save_steps SAVE_STEPS] [--only_save_embeds]\n",
            "                           --pretrained_model_name_or_path PRETRAINED_MODEL_NAME_OR_PATH\n",
            "                           [--revision REVISION] [--tokenizer_name TOKENIZER_NAME]\n",
            "                           --train_data_dir TRAIN_DATA_DIR --placeholder_token PLACEHOLDER_TOKEN\n",
            "                           [--initialize_tokens [INITIALIZE_TOKENS ...]] [--celeb_path CELEB_PATH]\n",
            "                           --n_persudo_tokens N_PERSUDO_TOKENS [--reg_weight REG_WEIGHT]\n",
            "                           [--learnable_property LEARNABLE_PROPERTY] [--repeats REPEATS]\n",
            "                           [--output_dir OUTPUT_DIR] [--seed SEED] [--resolution RESOLUTION]\n",
            "                           [--center_crop] [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                           [--max_train_steps MAX_TRAIN_STEPS]\n",
            "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                           [--gradient_checkpointing] [--learning_rate LEARNING_RATE] [--scale_lr]\n",
            "                           [--lr_scheduler LR_SCHEDULER] [--lr_warmup_steps LR_WARMUP_STEPS]\n",
            "                           [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
            "                           [--adam_weight_decay ADAM_WEIGHT_DECAY] [--adam_epsilon ADAM_EPSILON]\n",
            "                           [--push_to_hub] [--hub_token HUB_TOKEN] [--hub_model_id HUB_MODEL_ID]\n",
            "                           [--logging_dir LOGGING_DIR] [--mixed_precision {no,fp16,bf16}]\n",
            "                           [--allow_tf32] [--report_to REPORT_TO]\n",
            "                           [--validation_prompt VALIDATION_PROMPT]\n",
            "                           [--validation_prompt_file VALIDATION_PROMPT_FILE]\n",
            "                           [--num_validation_images NUM_VALIDATION_IMAGES]\n",
            "                           [--validation_steps VALIDATION_STEPS]\n",
            "                           [--validation_epochs VALIDATION_EPOCHS] [--local_rank LOCAL_RANK]\n",
            "                           [--checkpointing_steps CHECKPOINTING_STEPS]\n",
            "                           [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
            "                           [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                           [--enable_xformers_memory_efficient_attention]\n",
            "train_cross_init.py: error: unrecognized arguments: \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --logging_dir \"/content/drive/MyDrive/CrossInitialization/logs/tensorboard\" \\"
      ],
      "metadata": {
        "id": "aChCbS7WcOoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from accelerate import Accelerator\n",
        "\n",
        "# accelerator = Accelerator(log_with=\"tensorboard\", project_dir='./output')\n",
        "\n",
        "!pip install git+https://github.com/huggingface/accelerate\n"
      ],
      "metadata": {
        "id": "KZ4q6oee4x0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c48111-e6c9-4012-d723-316d8e1d1595"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-wadoxhxp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-wadoxhxp\n",
            "  Resolved https://github.com/huggingface/accelerate to commit 415eddf1bee77da9ae0b98b1900a342c6a5a235a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0.dev0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.33.0.dev0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.33.0.dev0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0.dev0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.33.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.33.0.dev0-py3-none-any.whl size=315195 sha256=abaea49102dd76b860a263269c2ec3b24ef2321210394b4f7cb15e4121d77bb0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-__isxxct/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.20.3\n",
            "    Uninstalling accelerate-0.20.3:\n",
            "      Successfully uninstalled accelerate-0.20.3\n",
            "Successfully installed accelerate-0.33.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_cross_init.py --save_steps 100 --only_save_embeds --placeholder_token \"<Jordan>\" --train_batch_size 4 --scale_lr --n_persudo_tokens 2 --reg_weight \"1e-5\" --learning_rate 0.000625 --max_train_step 640 --train_data_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/jordan\" --celeb_path \"/content/drive/MyDrive/CrossInitialization/examples/wiki_names_v2.txt\" --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" --output_dir \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan\""
      ],
      "metadata": {
        "id": "W2e7EkIscOq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27b2b6a-ecc7-4fbf-923d-58ea15830a89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 16:27:02.330379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 16:27:02.330448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 16:27:02.447111: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 16:27:02.628166: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-26 16:27:03.752443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/26/2024 16:27:12 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.65MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 67.6MB/s]\n",
            "tokenizer/special_tokens_map.json: 100% 460/460 [00:00<00:00, 2.49MB/s]\n",
            "tokenizer/tokenizer_config.json: 100% 807/807 [00:00<00:00, 5.08MB/s]\n",
            "scheduler/scheduler_config.json: 100% 346/346 [00:00<00:00, 2.09MB/s]\n",
            "{'timestep_spacing', 'thresholding', 'clip_sample_range', 'sample_max_value', 'variance_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "text_encoder/config.json: 100% 613/613 [00:00<00:00, 3.63MB/s]\n",
            "model.safetensors: 100% 1.36G/1.36G [00:05<00:00, 259MB/s]\n",
            "vae/config.json: 100% 553/553 [00:00<00:00, 3.42MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 262MB/s]\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "unet/config.json: 100% 911/911 [00:00<00:00, 6.15MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 3.46G/3.46G [00:20<00:00, 169MB/s]\n",
            "{'addition_embed_type_num_heads', 'num_attention_heads', 'time_embedding_type', 'mid_block_only_cross_attention', 'encoder_hid_dim', 'resnet_out_scale_factor', 'time_embedding_act_fn', 'time_embedding_dim', 'conv_in_kernel', 'cross_attention_norm', 'conv_out_kernel', 'projection_class_embeddings_input_dim', 'transformer_layers_per_block', 'resnet_skip_time_act', 'upcast_attention', 'time_cond_proj_dim', 'class_embed_type', 'encoder_hid_dim_type', 'mid_block_type', 'class_embeddings_concat', 'dropout', 'resnet_time_scale_shift', 'timestep_post_act', 'attention_type', 'addition_time_embed_dim', 'addition_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "get embeddings: 100% 691/691 [00:00<00:00, 2590.09it/s]\n",
            "07/26/2024 16:27:54 - INFO - __main__ - ***** Running training *****\n",
            "07/26/2024 16:27:54 - INFO - __main__ -   Num examples = 100\n",
            "07/26/2024 16:27:54 - INFO - __main__ -   Num Epochs = 26\n",
            "07/26/2024 16:27:54 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
            "07/26/2024 16:27:54 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "07/26/2024 16:27:54 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "07/26/2024 16:27:54 - INFO - __main__ -   Total optimization steps = 640\n",
            "Steps:  16% 100/640 [05:36<30:03,  3.34s/it, embed_loss=3.23e-5, loss=0.148, lr=0.0025]07/26/2024 16:33:31 - INFO - __main__ - Saving embeddings\n",
            "Steps:  31% 200/640 [11:12<24:30,  3.34s/it, embed_loss=6.16e-5, loss=0.127, lr=0.0025]07/26/2024 16:39:07 - INFO - __main__ - Saving embeddings\n",
            "Steps:  47% 300/640 [16:49<18:56,  3.34s/it, embed_loss=9.18e-5, loss=0.398, lr=0.0025]07/26/2024 16:44:43 - INFO - __main__ - Saving embeddings\n",
            "Steps:  62% 400/640 [22:25<13:22,  3.34s/it, embed_loss=0.000115, loss=0.0385, lr=0.0025]07/26/2024 16:50:20 - INFO - __main__ - Saving embeddings\n",
            "Steps:  78% 500/640 [28:01<07:48,  3.34s/it, embed_loss=0.000134, loss=0.126, lr=0.0025]07/26/2024 16:55:56 - INFO - __main__ - Saving embeddings\n",
            "07/26/2024 16:55:56 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/checkpoint-500\n",
            "07/26/2024 16:56:07 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/checkpoint-500/model.safetensors\n",
            "07/26/2024 16:56:09 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/checkpoint-500/optimizer.bin\n",
            "07/26/2024 16:56:09 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/checkpoint-500/scheduler.bin\n",
            "07/26/2024 16:56:09 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/checkpoint-500/sampler.bin\n",
            "07/26/2024 16:56:09 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/checkpoint-500/random_states_0.pkl\n",
            "07/26/2024 16:56:09 - INFO - __main__ - Saved state to /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/checkpoint-500\n",
            "Steps:  94% 600/640 [33:50<02:13,  3.33s/it, embed_loss=0.000155, loss=0.0411, lr=0.0025]07/26/2024 17:01:45 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 640/640 [36:05<00:00,  3.36s/it, embed_loss=0.000164, loss=0.219, lr=0.0025] 07/26/2024 17:04:00 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 640/640 [36:05<00:00,  3.38s/it, embed_loss=0.000164, loss=0.219, lr=0.0025]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_cross_init.py --save_steps 100 --only_save_embeds --placeholder_token \"<Trump>\" --train_batch_size 4 --scale_lr --n_persudo_tokens 2 --reg_weight \"1e-5\" --learning_rate 0.000625 --max_train_step 640 --train_data_dir \"/content/drive/MyDrive/CrossInitialization/examples/input_images/trump\" --celeb_path \"/content/drive/MyDrive/CrossInitialization/examples/wiki_names_v2.txt\" --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" --output_dir \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyWNFWkD2rZQ",
        "outputId": "3faa7ee4-54d9-4e0a-e291-02a954e52662"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 17:05:57.213432: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 17:05:57.213486: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 17:05:57.220900: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 17:05:57.234900: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-26 17:05:58.524329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/26/2024 17:06:01 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "{'clip_sample_range', 'timestep_spacing', 'sample_max_value', 'dynamic_thresholding_ratio', 'variance_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "{'addition_embed_type_num_heads', 'encoder_hid_dim', 'class_embed_type', 'projection_class_embeddings_input_dim', 'time_embedding_act_fn', 'cross_attention_norm', 'addition_time_embed_dim', 'encoder_hid_dim_type', 'addition_embed_type', 'time_cond_proj_dim', 'class_embeddings_concat', 'dropout', 'num_attention_heads', 'mid_block_only_cross_attention', 'resnet_time_scale_shift', 'conv_out_kernel', 'timestep_post_act', 'resnet_skip_time_act', 'transformer_layers_per_block', 'time_embedding_type', 'upcast_attention', 'attention_type', 'mid_block_type', 'time_embedding_dim', 'conv_in_kernel', 'resnet_out_scale_factor'} was not found in config. Values will be initialized to default values.\n",
            "get embeddings: 100% 691/691 [00:00<00:00, 2309.76it/s]\n",
            "07/26/2024 17:06:33 - INFO - __main__ - ***** Running training *****\n",
            "07/26/2024 17:06:33 - INFO - __main__ -   Num examples = 100\n",
            "07/26/2024 17:06:33 - INFO - __main__ -   Num Epochs = 26\n",
            "07/26/2024 17:06:33 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
            "07/26/2024 17:06:33 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "07/26/2024 17:06:33 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "07/26/2024 17:06:33 - INFO - __main__ -   Total optimization steps = 640\n",
            "Steps:  16% 100/640 [07:05<35:08,  3.91s/it, embed_loss=4.19e-5, loss=0.106, lr=0.0025]07/26/2024 17:13:38 - INFO - __main__ - Saving embeddings\n",
            "Steps:  31% 200/640 [14:09<29:08,  3.97s/it, embed_loss=7.01e-5, loss=0.0574, lr=0.0025]07/26/2024 17:20:42 - INFO - __main__ - Saving embeddings\n",
            "Steps:  47% 300/640 [21:13<22:44,  4.01s/it, embed_loss=8.82e-5, loss=0.219, lr=0.0025]07/26/2024 17:27:47 - INFO - __main__ - Saving embeddings\n",
            "Steps:  62% 400/640 [28:15<15:39,  3.91s/it, embed_loss=0.000109, loss=0.0456, lr=0.0025]07/26/2024 17:34:49 - INFO - __main__ - Saving embeddings\n",
            "Steps:  78% 500/640 [35:19<09:10,  3.93s/it, embed_loss=0.000129, loss=0.198, lr=0.0025]07/26/2024 17:41:53 - INFO - __main__ - Saving embeddings\n",
            "07/26/2024 17:41:53 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/checkpoint-500\n",
            "07/26/2024 17:42:01 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/checkpoint-500/model.safetensors\n",
            "07/26/2024 17:42:03 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/checkpoint-500/optimizer.bin\n",
            "07/26/2024 17:42:03 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/checkpoint-500/scheduler.bin\n",
            "07/26/2024 17:42:03 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/checkpoint-500/sampler.bin\n",
            "07/26/2024 17:42:03 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/checkpoint-500/random_states_0.pkl\n",
            "07/26/2024 17:42:03 - INFO - __main__ - Saved state to /content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/checkpoint-500\n",
            "Steps:  94% 600/640 [42:34<02:39,  3.98s/it, embed_loss=0.000151, loss=0.0779, lr=0.0025]07/26/2024 17:49:07 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 640/640 [45:24<00:00,  4.22s/it, embed_loss=0.000159, loss=0.223, lr=0.0025] 07/26/2024 17:51:57 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 640/640 [45:24<00:00,  4.26s/it, embed_loss=0.000159, loss=0.223, lr=0.0025]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cross_init.py \\\n",
        "    --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "    --num_inference_steps 50 \\\n",
        "    --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/learned_embeds-steps-100.bin\" \\\n",
        "    --prompt \"a photo of a {} person standing next to Trump\" \\\n",
        "    --save_dir \"/content/drive/MyDrive/CrossInitialization/jordan_images\" \\\n",
        "    --num_images_per_prompt=4 \\\n",
        "    --n_iter=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUOU1exK6qok",
        "outputId": "9899755f-7572-4e26-9bcc-c8adfe1133b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 17:52:40.704649: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 17:52:40.704705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 17:52:40.707613: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 17:52:41.949846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "model_index.json: 100% 543/543 [00:00<00:00, 3.62MB/s]\n",
            "Fetching 7 files:   0% 0/7 [00:00<?, ?it/s]\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 342/342 [00:00<00:00, 2.19MB/s]\n",
            "Fetching 7 files: 100% 7/7 [00:00<00:00, 13.47it/s]\n",
            "Loading pipeline components...: 100% 6/6 [00:19<00:00,  3.25s/it]\n",
            "100% 50/50 [00:22<00:00,  2.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cross_init.py \\\n",
        "    --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "    --num_inference_steps 50 \\\n",
        "    --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/learned_embeds-steps-100.bin\" \\\n",
        "    --prompt \"a photo of a {} person standing next to Jordan\" \\\n",
        "    --save_dir \"/content/drive/MyDrive/CrossInitialization/Trump_images\" \\\n",
        "    --num_images_per_prompt=4 \\\n",
        "    --n_iter=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYErR0y86q6u",
        "outputId": "2a3de49d-338c-4961-ea9c-a9951fdbb15d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-26 18:00:40.816091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-26 18:00:40.816146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-26 18:00:40.823119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-26 18:00:42.801113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 6/6 [00:22<00:00,  3.77s/it]\n",
            "100% 50/50 [00:22<00:00,  2.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd method"
      ],
      "metadata": {
        "id": "OVz54erPN17g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parser.add_argument(\"--learned_embedding_path_2\", type=str, required=True)\n",
        "\n",
        "# learned_embeds_1 = torch.load(args.learned_embedding_path)\n",
        "# token_1 = list(learned_embeds_1.keys())[0]\n",
        "# learned_embeds_1 = learned_embeds_1[token_1]\n",
        "\n",
        "\n",
        "# learned_embeds_2 = torch.load(args.learned_embedding_path_2)\n",
        "# token_2 = list(learned_embeds_2.keys())[0]\n",
        "# learned_embeds_2 = learned_embeds_2[token_2]\n",
        "# num_added_tokens = tokenizer.add_tokens([token_1, token_2])\n",
        "# if num_added_tokens == 2:\n",
        "#     text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "# else:\n",
        "#     raise ValueError(f\"The tokenizer already contains the token {token_1} or {token_2}.\")\n",
        "\n",
        "# text_encoder.get_input_embeddings().weight.data[tokenizer.convert_tokens_to_ids(token_1)] = learned_embeds_1\n",
        "# text_encoder.get_input_embeddings().weight.data[tokenizer.convert_tokens_to_ids(token_2)] = learned_embeds_2\n",
        "# prompts = [p.replace(\"{1}\", token_1).replace(\"{2}\", token_2) for p in args.prompt]\n",
        "# python test_cross_init.py \\\n",
        "#     --pretrained_model_name_or_path \"stabilityai/stable-diffusion-2-1-base\" \\\n",
        "#     --num_inference_steps 50 \\\n",
        "#     --learned_embedding_path \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingsJordan/learned_embeds.bin\" \\\n",
        "#     --learned_embedding_path_2 \"/content/drive/MyDrive/CrossInitialization/examples/learned_embeddingstrump/learned_embeds.bin\" \\\n",
        "#     --prompt \"a photo of a {1} person standing next to {2}\" \\\n",
        "#     --save_dir \"./output/jordan_trump_images\" \\\n",
        "#     --num_images_per_prompt=4 \\\n",
        "#     --n_iter=1"
      ],
      "metadata": {
        "id": "aP9XB_lLN1-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SRFkDExN2Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XGj2Y9A5N2IL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}